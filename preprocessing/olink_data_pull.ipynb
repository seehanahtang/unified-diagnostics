{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6290a2c-2f84-47d1-b96b-8268357e51cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dxpy\n",
    "import subprocess\n",
    "\n",
    "# Automatically discover dispensed dataset ID and load the dataset \n",
    "dispensed_dataset_id = dxpy.find_one_data_object(typename='Dataset', name='app*.dataset', folder='/', name_mode='glob')['id']\n",
    "\n",
    "# Get project ID\n",
    "project_id = dxpy.find_one_project()[\"id\"]\n",
    "dataset = (':').join([project_id, dispensed_dataset_id])\n",
    "\n",
    "cmd = [\"dx\", \"extract_dataset\", dataset, \"-ddd\", \"--delimiter\", \",\"]\n",
    "subprocess.check_call(cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df1d379a-3303-476a-a816-d31360e9918e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104/336538462.py:8: DtypeWarning: Columns (4,7,8,9,10,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_dict_df = pd.read_csv(data_dict_csv)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "data_dict_csv = glob.glob(os.path.join(path, \"*.data_dictionary.csv\"))[0]\n",
    "data_dict_df = pd.read_csv(data_dict_csv)\n",
    "data_dict_df.head()\n",
    "\n",
    "field_names = list(\n",
    "    data_dict_df.loc[data_dict_df[\"entity\"] == \"olink_instance_0\", \"name\"].values\n",
    ")\n",
    "\n",
    "field_names_str = [f\"olink_instance_0.{f}\" for f in field_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca2a0420-e13a-442c-9de5-620120a23938",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "config = pyspark.SparkConf().setAll([('spark.kryoserializer.buffer.max', '128'),('spark.sql.execution.arrow.pyspark.enabled','true')])  \n",
    "sc = pyspark.SparkContext(conf=config)\n",
    "spark = pyspark.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98291c27-3155-4615-9756-95505d09c690",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['dx', 'extract_dataset', 'project-J36kyb8JB5QV410jF8P3GjZ4:record-J36qY8jJzx44Bv6754b5zQfX', '--fields', '', '--delimiter', ',', '--output', 'olink_6.sql', '--sql']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m      2\u001b[0m field_names_protein \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(field_names_str[i\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m500\u001b[39m:\u001b[38;5;28mmin\u001b[39m((i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m500\u001b[39m, \u001b[38;5;28mlen\u001b[39m(field_names_str))])\n\u001b[1;32m      3\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdx\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextract_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--sql\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m ]\n\u001b[0;32m---> 15\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124molink_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.sql\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     18\u001b[0m     retrieve_sql \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/subprocess.py:415\u001b[0m, in \u001b[0;36mcheck_call\u001b[0;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cmd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    414\u001b[0m         cmd \u001b[38;5;241m=\u001b[39m popenargs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, cmd)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['dx', 'extract_dataset', 'project-J36kyb8JB5QV410jF8P3GjZ4:record-J36qY8jJzx44Bv6754b5zQfX', '--fields', '', '--delimiter', ',', '--output', 'olink_6.sql', '--sql']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    field_names_protein = \",\".join(field_names_str[i*500:min((i+1)*500, len(field_names_str))])\n",
    "    cmd = [\n",
    "    \"dx\",\n",
    "    \"extract_dataset\",\n",
    "    dataset,\n",
    "    \"--fields\",\n",
    "    field_names_protein,\n",
    "    \"--delimiter\",\n",
    "    \",\",\n",
    "    \"--output\",\n",
    "    f\"olink_{i}.sql\",\n",
    "    \"--sql\",\n",
    "    ]\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "    with open(f'olink_{i}.sql', 'r') as file:\n",
    "        retrieve_sql = file.read()\n",
    "\n",
    "    temp_df = spark.sql(retrieve_sql.strip(\";\"))\n",
    "    \n",
    "    pdf = temp_df.toPandas()\n",
    "    pdf.to_csv(f'olink_{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2638561e-ab38-46fe-8371-d287568e898a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb9a2a5-0db0-4088-8601-9b4f132e086c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
