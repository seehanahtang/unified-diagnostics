{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "782dbdf4-b551-407e-ada7-b22422fc640b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seehanah/.local/lib/python3.11/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a159e5-374d-45d3-aaee-b60154e26c32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35727/385363085.py:1: DtypeWarning: Columns (13,16,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/blood_protein_cancers_clean.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/blood_protein_cancers_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c5f4849-49da-4983-b579-8779f537e6ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# todo\n",
    "# 1. split into train test (80:20) based on breast cancer time to diagnosis\n",
    "# 2. in train, get 100 nearest neighbors of breast cancer patients using demographic features and most important features from XGBoost\n",
    "#     - use this cohort to apply optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4a3eb7a-991e-4928-aa53-19771b06db76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bin_breast_ttd(x):\n",
    "    if pd.isna(x):         return \"NA\"\n",
    "    if x <= 0:             return \"<0\"\n",
    "    if 0 < x <= 1:        return \"0-1\"   # 0 and 1 included\n",
    "    if 1 < x <= 5:         return \"1-5\"   # (1, 5]\n",
    "    return \">5\"\n",
    "\n",
    "def proportions(frame):\n",
    "    return (frame[\"_strata\"].value_counts(normalize=True)\n",
    "            .reindex([\"<0\",\"0-1\",\"1-5\",\">5\",\"NA\"])\n",
    "            .fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf0c944-3f77-404d-99c3-293cb822985d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"_strata\"] = df[\"breast_time_to_diagnosis\"].apply(bin_breast_ttd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "542f36a5-fe23-43e4-9f57-019db4320172",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall:\n",
      " <0     0.018983\n",
      "0-1    0.001642\n",
      "1-5    0.007265\n",
      ">5     0.012567\n",
      "NA     0.959543\n",
      "Name: _strata, dtype: float64\n",
      "Train:\n",
      " <0     0.018988\n",
      "0-1    0.001628\n",
      "1-5    0.007265\n",
      ">5     0.012572\n",
      "NA     0.959548\n",
      "Name: _strata, dtype: float64\n",
      "Test:\n",
      " <0     0.018964\n",
      "0-1    0.001698\n",
      "1-5    0.007265\n",
      ">5     0.012548\n",
      "NA     0.959524\n",
      "Name: _strata, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"_strata\"]\n",
    ")\n",
    "\n",
    "print(\"Overall:\\n\", proportions(df))\n",
    "print(\"Train:\\n\", proportions(train_df))\n",
    "print(\"Test:\\n\", proportions(test_df))\n",
    "\n",
    "# train_df = train_df.drop(columns=[\"_strata\"])\n",
    "# test_df  = test_df.drop(columns=[\"_strata\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f22fc3a9-7852-4631-b184-c37ded4a550a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"output/xgb_breast_cancer_top_100_features.txt\", 'r') as f:\n",
    "    top_feats = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cb6f6a81-2e01-4830-ad4f-a9c9104ee473",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/software/anaconda3/2023.07/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "TIME_COL = \"breast_time_to_diagnosis\"\n",
    "K = 5  # number of neighbors per positive row\n",
    "\n",
    "# --- Detect the single categorical feature from top_feats (or set explicitly) ---\n",
    "auto_cats = [c for c in top_feats if str(train_df[c].dtype) in (\"object\", \"category\")]\n",
    "\n",
    "CAT_FEAT = auto_cats[0]\n",
    "\n",
    "num_feats = [c for c in top_feats if c != CAT_FEAT]\n",
    "\n",
    "# --- Preprocessing: impute+scale numeric, impute+onehot categorical ---\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler())  # normalizes numeric features\n",
    "        ]), num_feats),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))\n",
    "        ]), [CAT_FEAT]),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    sparse_threshold=0.0,  # force dense output\n",
    ")\n",
    "\n",
    "# Fit preprocesser on ALL train rows to keep a single feature space\n",
    "preprocess.fit(train_df[top_feats])\n",
    "\n",
    "# --- Nearest neighbors: fit on negative rows, query with positive rows ---\n",
    "nn = NearestNeighbors(n_neighbors=K, metric=\"euclidean\", algorithm=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ec3eea78-ec77-4127-859d-73a160fd21a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (linux64 - \"CentOS Linux 7 (Core)\")\n",
      "\n",
      "CPU model: AMD EPYC 7352 24-Core Processor, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 48 physical cores, 48 logical processors, using up to 32 threads\n",
      "\n"
     ]
    },
    {
     "ename": "GurobiError",
     "evalue": "Model too large for size-limited license; visit https://gurobi.com/unrestricted for more information",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGurobiError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nA):\n\u001b[1;32m     44\u001b[0m     m\u001b[38;5;241m.\u001b[39maddConstr(gp\u001b[38;5;241m.\u001b[39mquicksum(x[i, j] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nB)) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mat_most_one_per_A[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m m\u001b[38;5;241m.\u001b[39moptimize()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nB):\n\u001b[1;32m     49\u001b[0m     matched_i \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nA) \u001b[38;5;28;01mif\u001b[39;00m x[i, j]\u001b[38;5;241m.\u001b[39mX \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m]\n",
      "File \u001b[0;32msrc/gurobipy/_model.pyx:903\u001b[0m, in \u001b[0;36mgurobipy._model.Model.optimize\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mGurobiError\u001b[0m: Model too large for size-limited license; visit https://gurobi.com/unrestricted for more information"
     ]
    }
   ],
   "source": [
    "#### run this first for sanity check ####\n",
    "\n",
    "matched = []\n",
    "strata = \"0-1\"\n",
    "# --- Identify negative vs positive subsets on the target column ---\n",
    "neg_mask = train_df[TIME_COL].isna()\n",
    "strata_mask = train_df[\"_strata\"] == strata\n",
    "df_neg = train_df.loc[neg_mask].copy()\n",
    "df_pos = train_df.loc[~neg_mask & strata_mask].copy()\n",
    "\n",
    "X_neg  = preprocess.transform(df_neg[top_feats])\n",
    "X_pos = preprocess.transform(df_pos[top_feats])\n",
    "\n",
    "nn.fit(X_neg)\n",
    "\n",
    "# For each positive row, get indices of K nearest negative rows (indices refer to df_neg order)\n",
    "distances, knn_indices = nn.kneighbors(X_pos, n_neighbors=K, return_distance=True)\n",
    "\n",
    "# Union of all negative neighbor indices across all positive rows\n",
    "neg_idx = np.unique(knn_indices)\n",
    "selected_neg_eid = df_neg.iloc[unique_neg_positions,:]['eid']\n",
    "\n",
    "# --- Result: the selected negative rows (union of neighbors) ---\n",
    "XA = X_pos\n",
    "XB = X_neg[neg_idx]\n",
    "nA, nB = XA.shape[0], XB.shape[0]\n",
    "\n",
    "# --- Matching: perform 2 to 1 matching on nearest neighbor subset ---\n",
    "cost = pairwise_distances(XA, XB, metric=\"euclidean\")\n",
    "\n",
    "m = gp.Model(\"two_to_one_matching\")\n",
    "\n",
    "# Binary decision vars: x[i,j] = 1 if A_i assigned to B_j\n",
    "x = m.addVars(nA, nB, vtype=GRB.BINARY, name=\"x\")\n",
    "\n",
    "# Objective: minimize total distance\n",
    "m.setObjective(gp.quicksum(cost[i, j] * x[i, j] for i in range(nA) for j in range(nB)),\n",
    "               GRB.MINIMIZE)\n",
    "\n",
    "# Each B_j gets exactly two A_i\n",
    "for j in range(nB):\n",
    "    m.addConstr(gp.quicksum(x[i, j] for i in range(nA)) == 2, name=f\"two_per_B[{j}]\")\n",
    "\n",
    "# Each A_i is used at most once\n",
    "for i in range(nA):\n",
    "    m.addConstr(gp.quicksum(x[i, j] for j in range(nB)) <= 1, name=f\"at_most_one_per_A[{i}]\")\n",
    "\n",
    "m.optimize()\n",
    "\n",
    "for j in range(nB):\n",
    "    matched_i = [i for i in range(nA) if x[i, j].X > 0.5]\n",
    "    if len(matched_i) > 0:\n",
    "        matched.append(selected_neg_eid[matched_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db48b4d8-82db-4ca3-a228-e4c79552a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched = []\n",
    "\n",
    "for strata in [\"<0\",\"0-1\",\"1-5\",\">5\"]:\n",
    "\n",
    "    # --- Identify negative vs positive subsets on the target column ---\n",
    "    neg_mask = train_df[TIME_COL].isna()\n",
    "    strata_mask = train_df[\"_strata\"] == strata\n",
    "    df_neg = train_df.loc[neg_mask].copy()\n",
    "    df_pos = train_df.loc[~neg_mask & strata_mask].copy()\n",
    "\n",
    "    X_neg  = preprocess.transform(df_neg[top_feats])\n",
    "    X_pos = preprocess.transform(df_pos[top_feats])\n",
    "\n",
    "    nn.fit(X_neg)\n",
    "\n",
    "    # For each positive row, get indices of K nearest negative rows (indices refer to df_neg order)\n",
    "    distances, knn_indices = nn.kneighbors(X_pos, n_neighbors=K, return_distance=True)\n",
    "\n",
    "    # Union of all negative neighbor indices across all positive rows\n",
    "    neg_idx = np.unique(knn_indices)\n",
    "    #selected_neg_eid = df_neg.iloc[unique_neg_positions,:]['eid']\n",
    "\n",
    "    # --- Result: the selected negative rows (union of neighbors) ---\n",
    "    XA = X_pos\n",
    "    XB = X_neg[neg_idx]\n",
    "    nA, nB = XA.shape[0], XB.shape[0]\n",
    "    \n",
    "    # --- Matching: perform 2 to 1 matching on nearest neighbor subset ---\n",
    "    cost = pairwise_distances(XA, XB, metric=\"euclidean\")\n",
    "\n",
    "    m = gp.Model(\"two_to_one_matching\")\n",
    "\n",
    "    # Binary decision vars: x[i,j] = 1 if A_i assigned to B_j\n",
    "    x = m.addVars(nA, nB, vtype=GRB.BINARY, name=\"x\")\n",
    "\n",
    "    # Objective: minimize total distance\n",
    "    m.setObjective(gp.quicksum(cost[i, j] * x[i, j] for i in range(nA) for j in range(nB)),\n",
    "                   GRB.MINIMIZE)\n",
    "\n",
    "    # Each B_j gets exactly two A_i\n",
    "    for i in range(nA):\n",
    "        m.addConstr(gp.quicksum(x[i, j] for j in range(nB)) == 2, name=f\"two_per_A[{i}]\")\n",
    "    \n",
    "    # Each A_i is used at most once\n",
    "    for j in range(nB):\n",
    "        m.addConstr(gp.quicksum(x[i, j] for i in range(nA)) <= 1, name=f\"at_most_one_per_A[{i}]\")\n",
    "    \n",
    "    m.optimize()\n",
    "    \n",
    "    for i in range(nA):\n",
    "        matched_j = [j for j in range(nB) if x[i, j].X > 0.5]\n",
    "        if len(matched_j) > 0:\n",
    "            matched = matched + list(neg_idx[matched_j])\n",
    "    selected_eid = df_neg.iloc[matched,:][['eid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c5f343b-6bab-41ed-bf4b-8c687534edb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_neg = pd.read_csv(\"data/breast_cancer_matched_negative.csv\")\n",
    "train_pos = pd.read_csv(\"data/breast_cancer_matched_positive.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa626a4c-66a5-4fbb-b0a7-65df4d68ca1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35727/4151512519.py:6: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_eids = (train_pos[\"eid\"].append(train_neg[\"eid\"])).astype(int)\n"
     ]
    }
   ],
   "source": [
    "PROP = len(train_neg) / len(train_pos)\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# --- Train set from successful matches (A and B) ---\n",
    "train_eids = (train_pos[\"eid\"].append(train_neg[\"eid\"])).astype(int)\n",
    "train_part = pd.DataFrame({\"eid\": train_eids, \"train\": 1})\n",
    "\n",
    "# --- Test set: all NOT-NA rows, plus 2x as many NA rows sampled at random ---\n",
    "test_notna_eids = test_df.loc[test_df[TIME_COL].notna(), \"eid\"]\n",
    "test_na_pool_eids = test_df.loc[test_df[TIME_COL].isna(), \"eid\"]\n",
    "\n",
    "n_notna = len(test_notna_eids)\n",
    "\n",
    "test_na_sampled = pd.Index(rng.choice(test_na_pool_eids.values, size=int(PROP*n_notna), replace=False))\n",
    "\n",
    "test_eids_final = pd.concat([\n",
    "    pd.Series(test_notna_eids, dtype=test_na_sampled.dtype),\n",
    "    pd.Series(test_na_sampled, dtype=test_na_sampled.dtype)\n",
    "], ignore_index=True)\n",
    "test_part = pd.DataFrame({\"eid\": test_eids_final, \"train\": 0})\n",
    "\n",
    "# --- Final dataframe ---\n",
    "final_df = pd.concat([train_part, test_part], ignore_index=True)\n",
    "final_df.to_csv(\"data/breast_cancer_matched_eids.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2d18fc-3f36-4352-b254-1da433e953dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
